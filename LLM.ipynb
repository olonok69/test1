{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86e71d55-aca3-4cca-9e87-8f738dcc82ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==1.12.0 in /home/olonok/.local/lib/python3.11/site-packages (1.12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/olonok/.local/lib/python3.11/site-packages (from openai==1.12.0) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/olonok/.local/lib/python3.11/site-packages (from openai==1.12.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/olonok/.local/lib/python3.11/site-packages (from openai==1.12.0) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/olonok/.local/lib/python3.11/site-packages (from openai==1.12.0) (1.10.13)\n",
      "Requirement already satisfied: sniffio in /home/olonok/.local/lib/python3.11/site-packages (from openai==1.12.0) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/olonok/.local/lib/python3.11/site-packages (from openai==1.12.0) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/olonok/.local/lib/python3.11/site-packages (from openai==1.12.0) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/olonok/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai==1.12.0) (3.6)\n",
      "Requirement already satisfied: certifi in /home/olonok/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /home/olonok/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.12.0) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/olonok/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.12.0) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==1.12.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a859e5eb-ea68-4497-bf14-b8ceb1d79049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olonok/.local/lib/python3.11/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df002890-d031-452d-b0fe-23c464a9228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef0a8a4-3ef2-491e-bcc4-809e265412eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/olonok/mlflow/mlruns/3', creation_time=1715346281897, experiment_id='3', last_update_time=1715346281897, lifecycle_stage='active', name='openai-evaluate', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"openai-evaluate\"\n",
    "try:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "except:\n",
    "    print(\"experiment exists\")\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "253caef5-50a5-45f6-aa2f-f1d8f194ad77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e100b009-34cb-483e-a94b-cc8c64f658ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "478be2fd-072a-458a-b886-872dc6f11aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Spark?\",\n",
    "        ],\n",
    "        \"ground_truth\": [\n",
    "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) \"\n",
    "            \"lifecycle. It was developed by Databricks, a company that specializes in big data and \"\n",
    "            \"machine learning solutions. MLflow is designed to address the challenges that data \"\n",
    "            \"scientists and machine learning engineers face when developing, training, and deploying \"\n",
    "            \"machine learning models.\",\n",
    "            \"Apache Spark is an open-source, distributed computing system designed for big data \"\n",
    "            \"processing and analytics. It was developed in response to limitations of the Hadoop \"\n",
    "            \"MapReduce computing model, offering improvements in speed and ease of use. Spark \"\n",
    "            \"provides libraries for various tasks such as data ingestion, processing, and analysis \"\n",
    "            \"through its components like Spark SQL for structured data, Spark Streaming for \"\n",
    "            \"real-time data processing, and MLlib for machine learning tasks\",\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28c73731-3944-4d6e-8d70-1e3e7a234dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5cdb47e-5b2b-4a9f-9852-4dc64cb0ec78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Completions.create of <openai.resources.chat.completions.Completions object at 0x7f575dbff050>>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.chat.completions.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11015cfa-4533-405c-860a-2f11ced78e23",
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Unsupported task type: <class 'openai.resources.chat.completions.Completions'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer the following question in two sentences\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Wrap \"gpt-4\" as an MLflow model.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m logged_model_info \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{question}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Use predefined question-answering metrics to evaluate our model.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m results \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m     16\u001b[0m     logged_model_info\u001b[38;5;241m.\u001b[39mmodel_uri,\n\u001b[1;32m     17\u001b[0m     eval_data,\n\u001b[1;32m     18\u001b[0m     targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion-answering\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/openai/__init__.py:543\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(model, task, artifact_path, conda_env, code_paths, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, example_no_conversion, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;129m@experimental\u001b[39m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39mFLAVOR_NAME))\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_model\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    464\u001b[0m ):\n\u001b[1;32m    465\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    Log an OpenAI model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m            print(model.predict([\"hello\", \"world\"]))\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopenai\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_no_conversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_no_conversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/models/model.py:622\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m     (tracking_uri \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabricks\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m get_uri_scheme(tracking_uri) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabricks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignature\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    620\u001b[0m ):\n\u001b[1;32m    621\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(_LOG_MODEL_MISSING_SIGNATURE_WARNING)\n\u001b[0;32m--> 622\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39mlog_artifacts(local_path, mlflow_model\u001b[38;5;241m.\u001b[39martifact_path, run_id)\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/openai/__init__.py:339\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, task, path, conda_env, code_paths, mlflow_model, signature, input_example, pip_requirements, extra_pip_requirements, metadata, example_no_conversion, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m _validate_and_prepare_target_save_path(path)\n\u001b[1;32m    338\u001b[0m code_dir_subpath \u001b[38;5;241m=\u001b[39m _validate_and_copy_code_paths(code_paths, path)\n\u001b[0;32m--> 339\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[43m_get_task_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mlflow_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     mlflow_model \u001b[38;5;241m=\u001b[39m Model()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/mlflow/openai/__init__.py:179\u001b[0m, in \u001b[0;36m_get_task_name\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _class_to_task(task)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mMlflowException(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported task type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(task)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE\n\u001b[1;32m    181\u001b[0m     )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Unsupported task type: <class 'openai.resources.chat.completions.Completions'>"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    system_prompt = \"Answer the following question in two sentences\"\n",
    "    # Wrap \"gpt-4\" as an MLflow model.\n",
    "    logged_model_info = mlflow.openai.log_model(\n",
    "        model=\"gpt-4\",\n",
    "        task=client.chat.completions,\n",
    "        artifact_path=\"model\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": \"{question}\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Use predefined question-answering metrics to evaluate our model.\n",
    "    results = mlflow.evaluate(\n",
    "        logged_model_info.model_uri,\n",
    "        eval_data,\n",
    "        targets=\"ground_truth\",\n",
    "        model_type=\"question-answering\",\n",
    "    )\n",
    "    print(f\"See aggregated evaluation results below: \\n{results.metrics}\")\n",
    "\n",
    "    # Evaluation result for each data record is available in `results.tables`.\n",
    "    eval_table = results.tables[\"eval_results_table\"]\n",
    "    print(f\"See evaluation table below: \\n{eval_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a0710d-d5a8-429a-ac33-5f00e4777309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
